{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1dc7535634fb40149d9541892fd755d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_359b9eafe8434fe3b413c9e13510a3ea",
              "IPY_MODEL_19a3d4eac9f34996aded3048e8ebe246",
              "IPY_MODEL_c7f692a48e844034842c26e037af23d8"
            ],
            "layout": "IPY_MODEL_0d5eacf16be84752a69e4d1a395f9680"
          }
        },
        "359b9eafe8434fe3b413c9e13510a3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58c8f1cb6fe44f1e85beaf4efda3d34d",
            "placeholder": "​",
            "style": "IPY_MODEL_dfe3106bf3254d0db4e809c46c4d3406",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "19a3d4eac9f34996aded3048e8ebe246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf2564aa2cb485080c669f4d1501806",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc72f57e1ea14533869760c29e552ac3",
            "value": 2
          }
        },
        "c7f692a48e844034842c26e037af23d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db632d5d03545ceb7a02f80a9ce35dd",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea274a7d16c4a7c8cd35300f2dc0da2",
            "value": " 2/2 [01:16&lt;00:00, 35.26s/it]"
          }
        },
        "0d5eacf16be84752a69e4d1a395f9680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c8f1cb6fe44f1e85beaf4efda3d34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe3106bf3254d0db4e809c46c4d3406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf2564aa2cb485080c669f4d1501806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc72f57e1ea14533869760c29e552ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db632d5d03545ceb7a02f80a9ce35dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea274a7d16c4a7c8cd35300f2dc0da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MediChat : AI Health Assistant Chatbot**\n",
        "\n",
        "This project developed a creative AI-powered medical chatbot to support users with health-related questions. By fine-tuning a language model on a specialized medical dataset, the chatbot provides accurate and reliable answers tailored to user queries. A streamlined Gradio interface allows users of all skill levels to easily input questions and receive clear, practical responses. Built in Python, the project focuses on efficiency and flexibility, optimizing the model to deliver dependable health guidance in an accessible, user-friendly way, enhancing access to healthcare information.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Pq0ZJ-E0mSrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Installing Unsloth**\n",
        "\n",
        "Installs unsloth and its latest version from GitHub for model loading and fine-tuning."
      ],
      "metadata": {
        "id": "vDmhPCfxfgU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth # install unsloth\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!"
      ],
      "metadata": {
        "id": "eu_tnkMe4aMt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "3e214a2f-9a27-407e-ca13-7a75c048d190"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.3.19)\n",
            "Collecting git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-y7m5kf7y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-y7m5kf7y\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 6c234d5a66adb76b9b93fb0f2445648199d88e66\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.3.19-py3-none-any.whl size=192661 sha256=e11f2636d3333bbda6c6dd81153088aa8c64d0522b4774d464ebba3ef9b48a8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fks14d8v/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "  Attempting uninstall: unsloth\n",
            "    Found existing installation: unsloth 2025.3.19\n",
            "    Uninstalling unsloth-2025.3.19:\n",
            "      Successfully uninstalled unsloth-2025.3.19\n",
            "Successfully installed unsloth-2025.3.19\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "unsloth"
                ]
              },
              "id": "74afe2a447e6461ca79ee66fc7ef380a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**  \n",
        "Imports libraries for model loading, fine-tuning, and dataset handling."
      ],
      "metadata": {
        "id": "_0Dl4T5NiB4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3: Import necessary libraries\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from unsloth import is_bfloat16_supported\n",
        "from huggingface_hub import login\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import wandb"
      ],
      "metadata": {
        "id": "0OPC1RC-5-cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44b34e6-4b57-491d-cebb-3d3096d83e08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Hugging Face Token**   \n",
        "Authenticates with Hugging Face using a token stored in Colab secrets."
      ],
      "metadata": {
        "id": "RBVB66HviNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step4: Check HF token\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "QiV2rrmy6HVm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check GPU Availability**\n",
        "\n",
        "Verifies CUDA and GPU availability on Colab."
      ],
      "metadata": {
        "id": "Yl-Ss3Hxibqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "43w_iFnd6Hfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86add01-1342-4afa-88c4-79b89aacaa0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Pretrained Model**\n",
        "\n",
        "Loads the deepseek-ai/deepseek-llm-7b-chat model with 4-bit quantization (7B Parameters)."
      ],
      "metadata": {
        "id": "AKsBwHPTitI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step5: Setup pretrained DeepSeek-R1\n",
        "\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
        "max_sequence_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ],
      "metadata": {
        "id": "lK9Rp43r6Ho9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "1dc7535634fb40149d9541892fd755d2",
            "359b9eafe8434fe3b413c9e13510a3ea",
            "19a3d4eac9f34996aded3048e8ebe246",
            "c7f692a48e844034842c26e037af23d8",
            "0d5eacf16be84752a69e4d1a395f9680",
            "58c8f1cb6fe44f1e85beaf4efda3d34d",
            "dfe3106bf3254d0db4e809c46c4d3406",
            "bdf2564aa2cb485080c669f4d1501806",
            "bc72f57e1ea14533869760c29e552ac3",
            "4db632d5d03545ceb7a02f80a9ce35dd",
            "9ea274a7d16c4a7c8cd35300f2dc0da2"
          ]
        },
        "outputId": "12ed74e2-71d2-4309-94c2-e1ed64f897d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dc7535634fb40149d9541892fd755d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deepseek-ai/deepseek-llm-7b-chat does not have a padding token! Will use pad_token = <|PAD_TOKEN|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define System Prompt**\n",
        "\n",
        "Sets up a prompt template for medical question-answering."
      ],
      "metadata": {
        "id": "4ETTAOeWjVPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6: Setup system prompt\n",
        "prompt_style = \"\"\"\n",
        "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
        "\n",
        "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
        "\n",
        "### Task:\n",
        "You are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "<think>{}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A6ukIo2V7_l_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run Inference (Pre-Fine-Tuning)**\n",
        "\n",
        "Tests the pretrained model with a medical question about cystometry."
      ],
      "metadata": {
        "id": "Uthw6Of7jhay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step7: Run Inference on the model\n",
        "\n",
        "# Define a test question\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\n",
        "              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "5bOmb_UT7_yG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38edce74-ff60-4d9c-a6b9-2787ec648f82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"<｜begin▁of▁sentence｜>\\nBelow is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\\n\\nBefore crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\\n\\n### Task:\\nYou are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\\n\\n### Query:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\\n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\\n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Answer:\\n<think>\\n\\n1. First, understand the context: The patient is a 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night. She has undergone a gynecological exam and Q-tip test.\\n\\n2. Consider the gynecological exam: The gynecological exam may provide information on the patient's pelvic organs, such as the uterus, ovaries, and fallopian tubes.\\n\\n3. Consider the Q-tip test: The Q-tip test is a way to measure the patient's residual volume, which is the volume of urine remaining in the bladder after a patient has voided. The test may also provide information on the patient's detrusor contractions, which are the involuntary contractions of the detrusor muscle that control bladder emptying.\\n\\n4. Analyze the results: Based on the gynecological exam and Q-tip test, cystometry most likely reveals that the patient has a small residual volume and that her detrusor contractions are weak. This is because the patient has involuntary urine loss during activities like coughing or sneezing but no leakage at night, which suggests a small residual volume. Additionally, the patient's history of involuntary urine loss during activities suggests weak detrusor contractions.\\n\\n5. Provide a response: The patient most likely has a small residual volume and weak detrusor contractions, which are consistent with a diagnosis of overactive bladder. Further testing and evaluation may be necessary to confirm this diagnosis and develop an appropriate treatment plan.\\n\\n<response>\\nBased on the gynecological exam and Q-tip test, cystometry most likely reveals that the patient has a small residual volume and that her detrusor contractions are weak. This suggests a diagnosis of overactive bladder. Further testing and evaluation may be necessary to confirm this diagnosis and develop an appropriate treatment plan.<｜end▁of▁sentence｜>\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[0].split(\"### Answer:\")[1])"
      ],
      "metadata": {
        "id": "yXlYCXSBJuIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da710525-9e90-46b8-b64f-33b92b813d29"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<think>\n",
            "\n",
            "1. First, understand the context: The patient is a 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night. She has undergone a gynecological exam and Q-tip test.\n",
            "\n",
            "2. Consider the gynecological exam: The gynecological exam may provide information on the patient's pelvic organs, such as the uterus, ovaries, and fallopian tubes.\n",
            "\n",
            "3. Consider the Q-tip test: The Q-tip test is a way to measure the patient's residual volume, which is the volume of urine remaining in the bladder after a patient has voided. The test may also provide information on the patient's detrusor contractions, which are the involuntary contractions of the detrusor muscle that control bladder emptying.\n",
            "\n",
            "4. Analyze the results: Based on the gynecological exam and Q-tip test, cystometry most likely reveals that the patient has a small residual volume and that her detrusor contractions are weak. This is because the patient has involuntary urine loss during activities like coughing or sneezing but no leakage at night, which suggests a small residual volume. Additionally, the patient's history of involuntary urine loss during activities suggests weak detrusor contractions.\n",
            "\n",
            "5. Provide a response: The patient most likely has a small residual volume and weak detrusor contractions, which are consistent with a diagnosis of overactive bladder. Further testing and evaluation may be necessary to confirm this diagnosis and develop an appropriate treatment plan.\n",
            "\n",
            "<response>\n",
            "Based on the gynecological exam and Q-tip test, cystometry most likely reveals that the patient has a small residual volume and that her detrusor contractions are weak. This suggests a diagnosis of overactive bladder. Further testing and evaluation may be necessary to confirm this diagnosis and develop an appropriate treatment plan.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Medical Dataset**\n",
        "\n",
        "Loads a medical dataset for fine-tuning."
      ],
      "metadata": {
        "id": "tDy28dX6jxRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step8: Setup fine-tuning\n",
        "\n",
        "# Load Dataset\n",
        "medical_dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split = \"train[:500]\", trust_remote_code = True)"
      ],
      "metadata": {
        "id": "rP-92kDoJuLV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_dataset[1]"
      ],
      "metadata": {
        "id": "5XPV24w-J4c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6051e547-8c86-4871-ae54-3cfa0f16243d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Question': 'A 33-year-old woman is brought to the emergency department 15 minutes after being stabbed in the chest with a screwdriver. Given her vital signs of pulse 110/min, respirations 22/min, and blood pressure 90/65 mm Hg, along with the presence of a 5-cm deep stab wound at the upper border of the 8th rib in the left midaxillary line, which anatomical structure in her chest is most likely to be injured?',\n",
              " 'Complex_CoT': \"Okay, let's figure out what's going on here. A woman comes in with a stab wound from a screwdriver. It's in her chest, upper border of the 8th rib, left side, kind of around the midaxillary line. First thought, that's pretty close to where the lung sits, right?\\n\\nLet's talk about location first. This spot is along the left side of her body. Above the 8th rib, like that, is where a lot of important stuff lives, like the bottom part of the left lung, possibly the diaphragm too, especially considering how deep the screwdriver went.\\n\\nThe wound is 5 cm deep. That sounds pretty deep. I mean, it could definitely reach down to the lung tissue or maybe the diaphragm. Given that it's midaxillary, we're in the territory where the lower lobe of the left lung hangs out. It's also possible there's some intersection with where the diaphragm begins, but the lung feels more probable somehow.\\n\\nNow, her vitals are concerning: elevated heart rate and low blood pressure. This is serious. My gut says that this kind of vital sign picture could mean something like pneumothorax or maybe hemothorax. Both can happen if the lung gets punctured, and they can make the blood pressure drop and the heart rate skyrocket since she's obviously distressed.\\n\\nSo, putting it all together, the most obvious culprit is the lower lobe of the left lung. The wound's depth and her condition point that way. And, yeah, this adds up with pneumothorax or maybe blood collecting in the chest—the kind of stuff that can really mess with breathing and circulation.\\n\\nAlright, with this in mind, it sure seems like the lung is the most likely thing that got hurt here. Makes sense given the situation, where the wound is, considering her symptoms, and the whole setup.\",\n",
              " 'Response': 'In this scenario, the most likely anatomical structure to be injured is the lower lobe of the left lung. The location of the stab wound—at the upper border of the 8th rib in the left midaxillary line—indicates proximity to the lower lobe of the lung. The depth of the wound (5 cm) suggests it is sufficient to reach lung tissue. Her vital signs of elevated heart rate and low blood pressure could signal complications like a pneumothorax or hemothorax, common consequences of lung trauma that would result from a penetrating injury in this area. Given these considerations, the lower lobe of the left lung is the most probable structure injured.'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define EOS Token**\n",
        "\n",
        "Retrieves the model’s end-of-sequence token."
      ],
      "metadata": {
        "id": "cBpoIibmkCJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which tells the model when to stop generating text during training\n",
        "EOS_TOKEN"
      ],
      "metadata": {
        "id": "fwkTUxMKJ4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1d27e1e4-f3a5-4b2c-8120-373037e13095"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<｜end▁of▁sentence｜>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Training Prompt**\n",
        "Sets up a prompt template for fine-tuning."
      ],
      "metadata": {
        "id": "XcHeGerFkKrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Finetuning\n",
        "# Updated training prompt style to add </think> tag\n",
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "jNUqVodgKFWz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess Dataset**\n",
        "\n",
        "Prepare the data for fine-tuning"
      ],
      "metadata": {
        "id": "TSdREu8dkVq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for fine-tuning\n",
        "\n",
        "def preprocess_input_data(examples):\n",
        "  inputs = examples[\"Question\"]\n",
        "  cots = examples[\"Complex_CoT\"]\n",
        "  outputs = examples[\"Response\"]\n",
        "\n",
        "  texts = []\n",
        "\n",
        "  for input, cot, output in zip(inputs, cots, outputs):\n",
        "    text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return {\n",
        "      \"texts\" : texts,\n",
        "  }"
      ],
      "metadata": {
        "id": "vPOUdCYSKFZ_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_dataset = medical_dataset.map(preprocess_input_data, batched = True)"
      ],
      "metadata": {
        "id": "Msg01aVNKNCx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_dataset[\"texts\"][0]"
      ],
      "metadata": {
        "id": "oOZ8r9zlKNFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b0f4e68a-4749-4b1d-f604-a464b095c3d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Below is an instruction that describes a task, paired with an input that provides further context.\\nWrite a response that appropriately completes the request.\\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\\nPlease answer the following medical question.\\n\\n### Question:\\nGiven the symptoms of sudden weakness in the left arm and leg, recent long-distance travel, and the presence of swollen and tender right lower leg, what specific cardiac abnormality is most likely to be found upon further evaluation that could explain these findings?\\n\\n### Response:\\n<think>\\nOkay, let's see what's going on here. We've got sudden weakness in the person's left arm and leg - and that screams something neuro-related, maybe a stroke?\\n\\nBut wait, there's more. The right lower leg is swollen and tender, which is like waving a big flag for deep vein thrombosis, especially after a long flight or sitting around a lot.\\n\\nSo, now I'm thinking, how could a clot in the leg end up causing issues like weakness or stroke symptoms?\\n\\nOh, right! There's this thing called a paradoxical embolism. It can happen if there's some kind of short circuit in the heart - like a hole that shouldn't be there.\\n\\nLet's put this together: if a blood clot from the leg somehow travels to the left side of the heart, it could shoot off to the brain and cause that sudden weakness by blocking blood flow there.\\n\\nHmm, but how would the clot get from the right side of the heart to the left without going through the lungs and getting filtered out?\\n\\nHere's where our cardiac anomaly comes in: a patent foramen ovale or PFO. That's like a sneaky little shortcut in the heart between the right and left atria.\\n\\nAnd it's actually pretty common, found in about a quarter of adults, which definitely makes it the top suspect here.\\n\\nSo with all these pieces - long travel, leg clot, sudden weakness - a PFO fits the bill perfectly, letting a clot cross over and cause all this.\\n\\nEverything fits together pretty neatly, so I'd bet PFO is the heart issue waiting to be discovered. Yeah, that really clicks into place!\\n</think>\\nThe specific cardiac abnormality most likely to be found in this scenario is a patent foramen ovale (PFO). This condition could allow a blood clot from the venous system, such as one from a deep vein thrombosis in the leg, to bypass the lungs and pass directly into the arterial circulation. This can occur when the clot moves from the right atrium to the left atrium through the PFO. Once in the arterial system, the clot can travel to the brain, potentially causing an embolic stroke, which would explain the sudden weakness in the left arm and leg. The connection between the recent travel, which increases the risk of deep vein thrombosis, and the neurological symptoms suggests the presence of a PFO facilitating a paradoxical embolism.<｜end▁of▁sentence｜>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply LoRA**\n",
        "\n",
        "Configures LoRA (Low-Rank Adaptation) for efficient fine-tuning."
      ],
      "metadata": {
        "id": "jCErpTT8khZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step9: Setup/Apply LoRA finetuning to the model\n",
        "\n",
        "model_lora = FastLanguageModel.get_peft_model(\n",
        "    model = model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3047,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")"
      ],
      "metadata": {
        "id": "AuHDDG5hKRli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fc85de-0f8e-47da-d3f8-5e9263d0aa44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.19 patched 30 layers with 30 QKV layers, 30 O layers and 30 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clear Model Attribute**\n",
        "\n",
        "Removes a potential conflicting attribute from the model"
      ],
      "metadata": {
        "id": "uGEbwAlOkpxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this before creating the trainer\n",
        "if hasattr(model, '_unwrapped_old_generate'):\n",
        "    del model._unwrapped_old_generate"
      ],
      "metadata": {
        "id": "KMCuLCXpKX77"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up Fine-Tuning Trainer**\n",
        "\n",
        "Configures the SFTTrainer for fine-tuning."
      ],
      "metadata": {
        "id": "ohoLOOiak00L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model_lora,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = finetune_dataset,\n",
        "    dataset_text_field = \"texts\",\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dataset_num_proc = 1,\n",
        "\n",
        "    # Define training args\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs = 1,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "7LwpYeQ-KX-o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up Weights & Biases (W&B)**\n",
        "\n",
        "Configures W&B for training monitoring."
      ],
      "metadata": {
        "id": "y3s1lUZMk9S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup WANDB\n",
        "from google.colab import userdata\n",
        "wnb_token = userdata.get(\"WANDB_TO_TOKEN\")\n",
        "# Login to WnB\n",
        "wandb.login(key=wnb_token) # import wandb\n",
        "run = wandb.init(\n",
        "    project='Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "BMOEgeSkKNH9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c7cc5b44-851b-490d-f9a7-d69cd42c5d93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkhanmoin1306\u001b[0m (\u001b[33mkhanmoin1306-lnmiit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250423_175718-bm6b72xh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/bm6b72xh?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3' target=\"_blank\">unique-jazz-2</a></strong> to <a href='https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3' target=\"_blank\">https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/bm6b72xh?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3' target=\"_blank\">https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/bm6b72xh?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start Fine-Tuning**\n",
        "\n",
        "Runs the fine-tuning process."
      ],
      "metadata": {
        "id": "Hwzn9SadlE64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the fine-tuning process\n",
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "p0YCdm9nKhhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "0ea17b23-68c3-47e4-8a31-c23a4a270473"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 37,478,400/7,000,000,000 (0.54% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 15:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.789600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.402100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.293800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.305100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finish W&B Run**\n",
        "\n",
        "Closes the W&B session."
      ],
      "metadata": {
        "id": "i0_fmecFlQ_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "ArlhoORCKssS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "8356dadb-8e28-4170-e612-4f5cea76eaea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▃▁▁▂▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1.5672031577653248e+16</td></tr><tr><td>train/epoch</td><td>0.96</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.12778</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3051</td></tr><tr><td>train_loss</td><td>1.40761</td></tr><tr><td>train_runtime</td><td>971.2012</td></tr><tr><td>train_samples_per_second</td><td>0.494</td></tr><tr><td>train_steps_per_second</td><td>0.062</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">unique-jazz-2</strong> at: <a href='https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/bm6b72xh?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3' target=\"_blank\">https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset/runs/bm6b72xh?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3</a><br> View project at: <a href='https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3' target=\"_blank\">https://wandb.ai/khanmoin1306-lnmiit/Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset?apiKey=2dc1bb82795d45354c76136b17195cc38689bec3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250423_175718-bm6b72xh/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Fine-Tuned Model (Cystometry)**\n",
        "\n",
        "Tests the fine-tuned model with the cystometry question."
      ],
      "metadata": {
        "id": "TPnlHqdTlVrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step10: Testing after fine-tuning\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing\n",
        "              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "OVYErAzhKhmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6989424-e29f-49b7-baed-4af8c0b003b6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"<｜begin▁of▁sentence｜>\\nBelow is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\\n\\nBefore crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\\n\\n### Task:\\nYou are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\\n\\n### Query:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing\\n              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\\n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Answer:\\n<think>\\nOkay, so we're dealing with a 61-year-old woman who's been dealing with some urinary incontinence for quite a while. This is pretty common, especially if she's had some involuntary urine loss during activities like coughing or sneezing. That's not so unusual, but when you think about it, it's important to dig deeper.\\n\\nNow, she had a gynecological exam, which might suggest something like a prolapse or some pelvic floor issues. But even though it's common to associate these kinds of symptoms with prolapse, it doesn't necessarily mean it's the root cause.\\n\\nThen, they do this Q-tip test. This is a bit more interesting. The Q-tip test is a way to measure the pressure inside the bladder. It's pretty straightforward: you stick a Q-tip in the urethra and see how long it takes for urine to leak out. The result can give a hint about how well the bladder is working.\\n\\nNow, considering all this, let's think about what we might expect from cystometry. Cystometry is a fancy term for watching what's happening inside the bladder. It's like a really detailed look at the way the bladder works.\\n\\nFirst, let's think about the residual volume. This is basically how much urine is left in the bladder after it's been emptied. If the Q-tip test shows that it takes a long time for the urine to leak out, this might indicate that the bladder is not emptying fully. In other words, it's not working at full capacity.\\n\\nBut wait, what about the detrusor contractions? These are the muscle contractions in the bladder that help push the urine out. If the bladder is not emptying fully, these contractions might not be as strong as they should be. That's because there's more urine left in there than the muscles can effectively push out.\\n\\nSo, based on the Q-tip test, we might expect the residual volume to be higher than normal. That could mean the bladder is not emptying as efficiently as it should. And if the bladder is not emptying fully, it could be an indication that the detrusor contractions might not be as strong as they should be.\\n\\nAll in all, cystometry would likely show that her residual volume is high and her detrusor contractions are not as strong as they should be. This supports the idea that there's more going on with her urinary function than just simple leakage.\\n</think>\\nBased on the Q-tip test results, cystometry is most likely to reveal that the residual volume is high, suggesting the bladder is not emptying fully. This, in turn, may indicate weak detrusor contractions, meaning the muscles responsible for pushing out urine are not functioning optimally. These findings support the idea that there is more to the urinary incontinence than just simple leakage and suggest a potential need for further investigation or treatment.<｜end▁of▁sentence｜>\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[0].split(\"### Answer:\")[1])"
      ],
      "metadata": {
        "id": "FToI2VLGKyYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1ebe9f-bbb3-4ec1-860c-10ed52810c60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<think>\n",
            "Okay, so we're dealing with a 61-year-old woman who's been dealing with some urinary incontinence for quite a while. This is pretty common, especially if she's had some involuntary urine loss during activities like coughing or sneezing. That's not so unusual, but when you think about it, it's important to dig deeper.\n",
            "\n",
            "Now, she had a gynecological exam, which might suggest something like a prolapse or some pelvic floor issues. But even though it's common to associate these kinds of symptoms with prolapse, it doesn't necessarily mean it's the root cause.\n",
            "\n",
            "Then, they do this Q-tip test. This is a bit more interesting. The Q-tip test is a way to measure the pressure inside the bladder. It's pretty straightforward: you stick a Q-tip in the urethra and see how long it takes for urine to leak out. The result can give a hint about how well the bladder is working.\n",
            "\n",
            "Now, considering all this, let's think about what we might expect from cystometry. Cystometry is a fancy term for watching what's happening inside the bladder. It's like a really detailed look at the way the bladder works.\n",
            "\n",
            "First, let's think about the residual volume. This is basically how much urine is left in the bladder after it's been emptied. If the Q-tip test shows that it takes a long time for the urine to leak out, this might indicate that the bladder is not emptying fully. In other words, it's not working at full capacity.\n",
            "\n",
            "But wait, what about the detrusor contractions? These are the muscle contractions in the bladder that help push the urine out. If the bladder is not emptying fully, these contractions might not be as strong as they should be. That's because there's more urine left in there than the muscles can effectively push out.\n",
            "\n",
            "So, based on the Q-tip test, we might expect the residual volume to be higher than normal. That could mean the bladder is not emptying as efficiently as it should. And if the bladder is not emptying fully, it could be an indication that the detrusor contractions might not be as strong as they should be.\n",
            "\n",
            "All in all, cystometry would likely show that her residual volume is high and her detrusor contractions are not as strong as they should be. This supports the idea that there's more going on with her urinary function than just simple leakage.\n",
            "</think>\n",
            "Based on the Q-tip test results, cystometry is most likely to reveal that the residual volume is high, suggesting the bladder is not emptying fully. This, in turn, may indicate weak detrusor contractions, meaning the muscles responsible for pushing out urine are not functioning optimally. These findings support the idea that there is more to the urinary incontinence than just simple leakage and suggest a potential need for further investigation or treatment.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Fine-Tuned Model (Aortic Valve)**\n",
        "\n",
        "Tests the fine-tuned model with a new question about aortic valve vegetation."
      ],
      "metadata": {
        "id": "G0JoeZ0Plpx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue,\n",
        "              and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative,\n",
        "              gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium.\n",
        "              What is the most likely predisposing factor for this patient's condition?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])"
      ],
      "metadata": {
        "id": "qk6kxR7vK3U2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e615e3-ddf3-496a-f3d7-5120bd560159"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<think>\n",
            "Alright, let's think about this. We have a 59-year-old man with some pretty classic symptoms: fever, chills, night sweats, and fatigue. That's pretty typical for a patient with endocarditis, which is inflammation of the heart valves.\n",
            "\n",
            "Now, endocarditis can be caused by various organisms, but let's start by looking at the blood cultures. These show gram-positive, catalase-negative, gamma-hemolytic cocci in chains. These are definitely clues because they fit the profile of Streptococcus viridans.\n",
            "\n",
            "Strep viridans is known for causing endocarditis, especially in those with prosthetic heart valves. That's because it's highly resistant to antibiotics and can hide in crevices around the valve.\n",
            "\n",
            "What's more, the organism doesn't grow in a 6.5% NaCl medium. That's a telltale sign that this is something called 'non-fastidious' or 'non-fermenting.' This means the bacteria are more likely to be found in a biofilm, which is a way of hiding out and avoiding antibiotics.\n",
            "\n",
            "So, taking all these clues together, it seems like the most likely cause of this patient's symptoms is endocarditis from Streptococcus viridans. This fits the profile of someone with a prosthetic valve who might have a biofilm around it, making them resistant to treatment.\n",
            "\n",
            "In conclusion, based on the blood cultures and the characteristics of the organism, I'm pretty confident this is endocarditis from Streptococcus viridans.\n",
            "</think>\n",
            "The most likely predisposing factor for the patient's condition is endocarditis due to Streptococcus viridans. This type of infection is typically seen in patients with prosthetic heart valves, especially when the valve is located in the aortic position. The presence of a 12 mm vegetation on the aortic valve and the characteristic growth characteristics of Streptococcus viridans on blood cultures are consistent with this diagnosis. Additionally, the fact that the organism does not grow in a 6.5% NaCl medium further supports this conclusion, as it is indicative of a biofilm formation which is common in Streptococcus viridans.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User Interface**\n",
        "\n",
        " Developed a user-friendly interface with Gradio, allowing seamless input of health prompts and display of informative responses,\n",
        " enhancing accessibility for non-technical users."
      ],
      "metadata": {
        "id": "xCfcVxigl49b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Install Gradio (skip if already installed)\n",
        "print(\"Installing Gradio...\")\n",
        "!pip install gradio --quiet\n",
        "print(\"Gradio installed.\")\n",
        "\n",
        "# Step 2: Import Gradio\n",
        "try:\n",
        "    import gradio as gr\n",
        "except ImportError as e:\n",
        "    raise ImportError(f\"Failed to import Gradio: {e}. Please ensure Gradio is installed.\")\n",
        "\n",
        "# Step 3: Placeholder chatbot function (no model loading)\n",
        "def ai_doctor_chatbot(question):\n",
        "    if not question.strip():\n",
        "        return \"Please enter a medical question.\"\n",
        "\n",
        "    # Placeholder response (replace with model inference after fixing notebook)\n",
        "    placeholder_response = (\n",
        "        \"This is a placeholder response because the fine-tuned model is not available. \"\n",
        "        \"To enable AI responses, please fix AI_Doctor_3.ipynb by updating Cell 7 with a valid model \"\n",
        "        \"(e.g., 'mistralai/Mixtral-8x7B-Instruct-v0.1'), re-run the notebook to generate the 'outputs' directory, \"\n",
        "        \"and then use the full Gradio script with model loading.\"\n",
        "    )\n",
        "\n",
        "    return f\"**Disclaimer**: This is an AI-generated response. Consult a doctor for professional medical advice.\\n\\n**Response**:\\n{placeholder_response}\"\n",
        "\n",
        "# Step 4: Create minimal Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=ai_doctor_chatbot,\n",
        "    inputs=gr.Textbox(\n",
        "        label=\"Ask a Medical Question\",\n",
        "        placeholder=\"E.g., What would cystometry reveal for stress urinary incontinence?\"\n",
        "    ),\n",
        "    outputs=gr.Textbox(label=\"Medichat Response\"),\n",
        "    title=\" MediChat: AI Health Assistant Chatbot\",\n",
        "    description=\"Get instant, reliable answers to your health-related questions. MediChat uses AI to provide supportive information based on real medical conversations.\",\n",
        "    theme=\"soft\",  # Clean, Grok-like aesthetic\n",
        "    allow_flagging=\"never\"  # Disable flagging for simplicity\n",
        ")\n",
        "\n",
        "# Step 5: Launch the interface\n",
        "print(\"Launching Gradio interface...\")\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "sxU-hKZ2KyN6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "5cfff204-8ca3-4aa6-bcc5-b8bd677ff042"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Gradio...\n",
            "Gradio installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Gradio interface...\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2e0b4ed589ad1e70fa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2e0b4ed589ad1e70fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}